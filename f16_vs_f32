import torch
import time

# Dimensions des matrices (ajuste selon ta VRAM)
M, N, K = 4096, 4096, 4096

def benchmark(dtype, label):
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()

    A = torch.rand((M, K), dtype=dtype, device='cuda')
    B = torch.rand((K, N), dtype=dtype, device='cuda')

    torch.cuda.synchronize()
    start = time.time()
    C = torch.matmul(A, B)
    torch.cuda.synchronize()
    end = time.time()

    used_memory_MB = torch.cuda.max_memory_allocated() / 1024**2
    elapsed = end - start
    gflops = 2 * M * N * K / (elapsed * 1e9)

    print(f"{label:<6}: {elapsed:.3f} s | {gflops:.2f} GFLOPS | {used_memory_MB:.1f} MB")

# Lancement des tests
print("Benchmark des formats de flottants :")
benchmark(torch.float16, 'float16')
benchmark(torch.float32, 'float32')
benchmark(torch.float64, 'float64')
