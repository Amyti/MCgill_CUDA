import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
from tqdm import tqdm
from sklearn.metrics import accuracy_score

transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])
trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)

class SimpleANN(nn.Module):
    def __init__(self):
        super(SimpleANN, self).__init__()
        self.fc1 = nn.Linear(28*28, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = torch.sigmoid(self.fc1(x))
        x = torch.sigmoid(self.fc2(x))
        x = self.fc3(x)
        return x

model = SimpleANN()

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)




def ann(trainloader, testloader, model, criterion, optimizer, epochs=10):
    Loss_train = []
    Acc_train = []
    Loss_test = []
    Acc_test = []

    for epoch in tqdm(range(epochs)):
        running_loss = 0
        all_preds = []
        all_labels = []

        model.train()
        for images, labels in trainloader:
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            preds = outputs.argmax(dim=1)
            all_preds.extend(preds.detach().cpu().numpy())
            all_labels.extend(labels.detach().cpu().numpy())

        acc = accuracy_score(all_labels, all_preds)
        Loss_train.append(running_loss / len(trainloader))
        Acc_train.append(acc)

        model.eval()
        test_loss = 0
        all_preds = []
        all_labels = []

        with torch.no_grad():
            for images, labels in testloader:
                outputs = model(images)
                loss = criterion(outputs, labels)
                test_loss += loss.item()
                preds = outputs.argmax(dim=1)
                all_preds.extend(preds.detach().cpu().numpy())
                all_labels.extend(labels.detach().cpu().numpy())

        acc = accuracy_score(all_labels, all_preds)
        Loss_test.append(test_loss / len(testloader))
        Acc_test.append(acc)

    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(Loss_train, label="train loss")
    plt.plot(Loss_test, label="test loss")
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(Acc_train, label="train acc")
    plt.plot(Acc_test, label="test acc")
    plt.legend()

    plt.show()

    model.eval()  # Mode évaluation pour le modèle

    images, labels = next(iter(testloader))  # Prendre un batch d'images de test

    outputs = model(images)  # Prédiction avec le modèle entraîné
    preds = outputs.argmax(dim=1)  # Prendre la classe prédite (valeur maximale)

    images = images / 2 + 0.5  # Dé-normaliser les images pour les rendre visibles

    fig, axes = plt.subplots(4, 4, figsize=(8, 8))
    for i in range(16):  # Montrer les 16 premières images
        ax = axes[i // 4, i % 4]
        ax.imshow(images[i].squeeze(), cmap='gray')
        ax.set_title(f"Pred: {preds[i].item()} / True: {labels[i].item()}")
        ax.axis('off')

    plt.tight_layout()
    plt.show()

    

    return model

model = ann(trainloader, testloader, model, criterion, optimizer, epochs=10)
