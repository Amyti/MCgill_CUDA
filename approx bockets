import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from tqdm import tqdm
import time
import bitstring

# reproducibility
seed = 42
torch.manual_seed(seed)
torch.cuda.manual_seed_all(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = True

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Data transforms and loaders
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

train_ds = datasets.MNIST('./data', train=True, download=True, transform=transform)
test_ds  = datasets.MNIST('./data', train=False, download=True, transform=transform)

train_loader = DataLoader(train_ds, batch_size=512, shuffle=True,  pin_memory=True)
test_loader  = DataLoader(test_ds,  batch_size=512, shuffle=False, pin_memory=True)

# MLP model definition
class sANN(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(28*28, 256)
        self.bn1 = nn.BatchNorm1d(256)
        self.dropout1 = nn.Dropout(0.2)
        self.fc2 = nn.Linear(256, 128)
        self.bn2 = nn.BatchNorm1d(128)
        self.dropout2 = nn.Dropout(0.2)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = torch.relu(self.bn1(self.dropout1(self.fc1(x))))
        x = torch.relu(self.bn2(self.dropout2(self.fc2(x))))
        return self.fc3(x)

# Approximation helpers
def reduce_mantissa_bits(val: float, bits_to_retain: int) -> float:
    bs = bitstring.pack('>f', val).bin  # IEEE-754 binary string
    sign = bs[0]
    exp = bs[1:9]
    mant = bs[9:9 + bits_to_retain]
    mant_value = 1 + int(mant, 2) / (1 << bits_to_retain)
    exp_value = int(exp, 2) - 127
    value = ((-1) ** int(sign)) * mant_value * (2 ** exp_value)
    return value

def bucketed_weights_forward(model: nn.Module, bits_per_bucket: int):
    for name, param in model.named_parameters():
        if not param.requires_grad:
            continue
        W = param.data.view(-1)
        w_min = W.abs().min().item()
        w_max = W.abs().max().item()
        B = int(torch.ceil(torch.tensor(23.0 / bits_per_bucket)).item())
        step = (w_max - w_min) / B
        bounds = [w_min + i * step for i in range(B + 1)]
        for i in range(W.numel()):
            w = W[i].item()
            a = abs(w)
            for b in range(1, B + 1):
                if a <= bounds[b]:
                    if b < B:
                        bits = b * bits_per_bucket
                        W[i] = reduce_mantissa_bits(w, bits)
                    break
        param.data.copy_(W.view_as(param.data))

# Training with bucketed forward approximation
def train_with_buckets(model, epochs=15, lr=1e-3, weight_decay=1e-4,
                       step_size=5, gamma=0.5, bits_per_bucket=5):
    model.to(device).train()
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)
    criterion = nn.CrossEntropyLoss()
    for epoch in range(epochs):
        loop = tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}")
        for images, labels in loop:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            bucketed_weights_forward(model, bits_per_bucket)
            loop.set_postfix(loss=loss.item())
        scheduler.step()
    return model

# Inference benchmark
def test_inference(model, dtype=torch.float32, runs=100):
    model.to(device).eval()
    if dtype == torch.float16:
        model.half()
    images, _ = next(iter(test_loader))
    images = images.to(device)
    if dtype == torch.float16:
        images = images.half()
    torch.cuda.reset_peak_memory_stats()
    torch.cuda.synchronize()
    # warm-up
    for _ in range(5):
        with torch.no_grad():
            _ = model(images)
    torch.cuda.synchronize()
    start = time.time()
    for _ in range(runs):
        with torch.no_grad():
            _ = model(images)
    torch.cuda.synchronize()
    avg_time = (time.time() - start) / runs
    peak_mem = torch.cuda.max_memory_allocated() / 1e6
    correct = 0
    total = 0
    with torch.no_grad():
        for imgs, labs in test_loader:
            imgs, labs = imgs.to(device), labs.to(device)
            if dtype == torch.float16:
                imgs = imgs.half()
            outputs = model(imgs)
            preds = outputs.argmax(dim=1)
            correct += (preds == labs).sum().item()
            total += labs.size(0)
    accuracy = 100.0 * correct / total
    return avg_time, peak_mem, accuracy

if __name__ == "__main__":
    print(f"Device: {device}")
    model = sANN()
    print("Training with bucketed approximation...")
    model = train_with_buckets(model, epochs=15, bits_per_bucket=5)
    torch.save(model.state_dict(), "model_bucketed.pth")

    print("\nInference FP32:")
    t32, m32, a32 = test_inference(model, torch.float32)
    print(f"Time: {t32*1e3:.2f} ms | Peak Mem: {m32:.1f} MB | Acc: {a32:.2f}%")

    print("\nInference FP16:")
    t16, m16, a16 = test_inference(model, torch.float16)
    print(f"Time: {t16*1e3:.2f} ms | Peak Mem: {m16:.1f} MB | Acc: {a16:.2f}%")

